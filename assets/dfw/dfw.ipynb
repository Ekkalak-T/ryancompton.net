{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import string\n",
      "import re\n",
      "import collections"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#first, run pdftotext on this:\n",
      "#http://nkelber.com/engl295/wp-content/uploads/2012/07/David-Foster-Wallace-Infinite-Jest-v2.0.pdf\n",
      "raw = open(\"David-Foster-Wallace-Infinite-Jest-v2.0.txt\",'rU').read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def vocabulary_size(raw):\n",
      "    \"\"\"\n",
      "    Compute the number of distinct words (stemmed)\n",
      "    ignores non-ascii letters\n",
      "    \"\"\"\n",
      "    #remove non-ascii letters\n",
      "    rec = re.compile('[^A-Za-z ]')\n",
      "    no_punct_lower = re.sub(rec,' ',raw).lower()\n",
      "    \n",
      "    #tokenize, stem, and count\n",
      "    tokens=nltk.word_tokenize(no_punct_lower)\n",
      "    stemmer = nltk.stem.PorterStemmer()\n",
      "    stemmed_tokens = []\n",
      "    for token in tokens:\n",
      "        stemmed_tokens.append(stemmer.stem(token))\n",
      "    return len(set(stemmed_tokens))\n",
      "\n",
      "print(\"words in vocabulary:\\t\",vocabulary_size(raw))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "words in vocabulary:\t 20584\n"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#http://www.englishclub.com/vocabulary/common-conjunctions-25.htm\n",
      "conjunctions = set(open('conjunctions.txt','rU').read().splitlines())\n",
      "print(\"num conjunctions in Wiktionary:\",len(conjunctions))\n",
      "\n",
      "prepositions = set(open('prepositions.txt','rU').read().splitlines())\n",
      "print(\"num prepositions in Wiktionary:\",len(prepositions))\n",
      "\n",
      "def longest_uninterrupted_seqs(raw, prep_conj, min_seq_length=3):\n",
      "    \"\"\"\n",
      "    Given a string of text and a set of terms to search for\n",
      "    return a count of how often uninterrupted seqs appear\n",
      "    \"\"\"\n",
      "    tokens = nltk.wordpunct_tokenize(raw)\n",
      "    longest_seq = []\n",
      "    all_seqs = []\n",
      "    for idx,token in enumerate(tokens):\n",
      "        tokl = token.lower()\n",
      "        if tokl in prep_conj:\n",
      "            seq = [tokl]\n",
      "            n_ahead = 0\n",
      "            while tokl in prep_conj:\n",
      "                n_ahead += 1\n",
      "                tokl = tokens[idx+n_ahead].lower()\n",
      "                if tokl in prep_conj:\n",
      "                    seq.append(tokl)\n",
      "            if len(seq) >= len(longest_seq):\n",
      "                longest_seq = seq\n",
      "            if len(seq) >= min_seq_length:\n",
      "                all_seqs.append(\" \".join(seq))\n",
      "    \n",
      "    #print most common term seqs\n",
      "    for common in collections.Counter(all_seqs).most_common(10):\n",
      "        print(common[0],'\\t',common[1])\n",
      "        \n",
      "    return longest_seq\n",
      "\n",
      "longest_seq = longest_uninterrupted_seqs(raw, prepositions.union(conjunctions), 3)\n",
      "print(\"longest sequence:\\t\",len(longest_seq), \" \".join(longest_seq))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "num conjunctions in Wiktionary: 191\n",
        "num prepositions in Wiktionary: 391\n",
        "and out of"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \t 41\n",
        "and so on \t 39\n",
        "up and down \t 32\n",
        "in and out of \t 30\n",
        "over and over \t 28\n",
        "up next to \t 24\n",
        "on and on \t 15\n",
        "up out of \t 14\n",
        "as in like \t 12\n",
        "come in and \t 12\n",
        "longest sequence:\t 7 up and down over and over for\n",
        "{'notwithstanding', 'in order that', 'OR', 'before', 'wherefore', 'yif', 'yet', 'nought withstanding', 'an if', 'else', 'bycause', 'wherever', 'inasmuch as', 'as a result', \"less'n\", 'neither', 'altho', '\u2010', 'andt', 'except', 'when', 'like as if', 'as', 'let alone', 'whereunto', 'now that', 'and', 'rather than', 'although', 'directly', \"'cuz\", 'ever since', 'in regard', 'after', \"'til\", 'minus', 'whereover', '\u2019n\u2019', 'provided', 'wheresoeer', 'whilst', 'thof', \"'cos\", 'whence', 'and/or', 'immediately', 'twell', 'forthy', 'whereas', 'unlesse', 'if so be', \"wheresoe'er\", 'label', 'on account of', 'whether', 'til', 'along with', 'as well as', 'thanne', 'not to mention', 'albethey', 'forasmuch as', 'whenever', 'noughtwithstanding', 'both', 'then', \"tho'\", 'being', 'why', 'however', 'that', 'but if', 'much less', 'ac', 'inasmuch', 'wherein', 'wherealong', 'as soon as', 'now', 'whenas', 'cus', 'though', 'zat', 'forthan', 'for that', 'thereas', 'till', 'xor', 'thobut', 'lest', 'as though', 'if', 'but', 'whereupon', 'either', '\u2019cause', 'whereinbefore', 'unto', \"'n'\", \"'cause\", 'kindof', \"n'\", 'because', 'affor', 'all the while', 'once', 'whilom', 'until', 'in so far as', 'choose', 'like as', 'insofar as', 'only if', 'unless', 'howsomever', 'being that', 'so that', 'whereat', 'nay', 'nor', 'ergo', 'howbeit', 'in that', 'forcause', 'since', 'having said that', 'for', \"'coz\", 'as if', 'precisely unless', 'forwhy', 'when, as, and if', 'where\u00e4s', 'albeit', 'sith', 'organized labour', 'b/c', 'hyphen', 'iffen', '&', 'whiles', 'only', 'iff', 'whilome', 'sithence', 'th\u00f4', 'yf', 'so', 'if and only if', 'or', 'and if', 'thatt', 'nd', 'ne', 'therfore', 'than', 'nought-withstanding', 'ifen', 'plus', 'without', 'on account', 'whither', 'tofore', 'wheresoever', 'dat', 'whereof', 'wheretoward', 'for to', 'outcept', 'gin', 'whereout', 'like as and', 'seeing', 'when as', 'to-whiles', 'against', 'but then', 'through until', 'even though', 'albe', 'not', 'slash', \"'cept\", 'followed by', 'as long as', 'where', 'bicause', 'save', 'wherethan', 'versus', 'while'}\n"
       ]
      }
     ],
     "prompt_number": 147
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.collocations.demo()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "firefox.txt\n",
        "\t"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ['download manager', 'http ://', 'new tab', 'context menu', 'address bar', 'print preview', 'location bar', 'mozilla firebird', 'bookmarks toolbar', 'password manager', 'new window', 'status bar', 'full screen', 'dom inspector', 'personal toolbar']\n",
        "\t Correlation to raw_freq: 0.6021"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "grail.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t ['black knight', 'clop clop', 'head knight', 'mumble mumble', 'squeak squeak', 'saw saw', 'holy grail', 'run away', 'french guard', 'cartoon character', 'iesu domine', 'pie iesu', 'round table', 'sir robin', 'clap clap']\n",
        "\t Correlation to raw_freq: 0.7946\n",
        "overheard.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ['teen girl', 'new york', 'teen boy', 'little boy', 'little girl', 'last night', 'old lady', 'old man', 'bus driver', 'long island', 'high school', 'drunk guy', 'look like', 'hipster girl', 'flight attendant']\n",
        "\t Correlation to raw_freq: 0.5210"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "pirates.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t ['jack sparrow', 'elizabeth swann', 'davy jones', 'flying dutchman', 'lord cutler', 'cutler beckett', 'black pearl', 'tia dalma', 'cannibal island', 'port royal', 'bamboo pole', 'edinburgh trader', 'east india', 'india trading', 'wounded sailor']\n",
        "\t Correlation to raw_freq: 0.6932\n",
        "singles.txt\n",
        "\t ['would like', 'age open', 'medium build', 'social drinker', 'non smoker', 'quiet nights', 'long term', 'easy going', 'poss rship', 'financially secure', 'fun times', 'weekends away', 'seeks lady', 'single dad', 'similar interests']\n",
        "\t Correlation to raw_freq: 0.6389\n",
        "wine.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t ['top ***', 'bare ****', 'bare ***', 'good length', 'bare ***(*)', 'medium weight', 'needs time', 'pretty good', 'mature claret', 'nice balance', 'red fruits', 'rather good', 'white burgundy', 'quite forward', 'top ****']\n",
        "\t Correlation to raw_freq: 0.5347"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}